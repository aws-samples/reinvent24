# KUB403 | High-Performance LLM Inference Scaling on Amazon EKS
Unlock the full potential of large language model (LLM) inference on Amazon EKS using leading open source frameworks. Learn to construct highly scalable, GPU-accelerated clusters with Amazon EKSâ€“optimized AMIs and NVIDIA CUDA runtimes. This chalk talk compares state-of-the-art open source inference engines with leading LLM frameworks. Explore performance metrics, auto scaling capabilities, NVIDIA GPU inference execution, and seamless integration with AWS services for maximum efficiency and scalability. 

## Session Resources 
[Slides](https://reinvent.awsevents.com/content/dam/reinvent/2024/slides/kub/KUB403_High-performance-LLM-inference-scaling-on-Amazon-EKS.pdf)

## Request an EKS Workshop
[AWS Guided EKS Workshop](https://pages.awscloud.com/NAMER-other-PT-eks-workshop-2024-reg.html?trk=93273282-cba3-45ac-932f-841b45264eee&sc_channel=el)
